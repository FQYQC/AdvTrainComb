{"cells":[{"cell_type":"markdown","metadata":{},"source":["# *Traffic Sign Recognizer - 99% accuracy*"]},{"cell_type":"markdown","metadata":{},"source":["## Importing Required Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import torch\n","# from tensorflow import keras\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score\n","np.random.seed(42)\n","\n","from matplotlib import style\n","style.use('fivethirtyeight')"]},{"cell_type":"markdown","metadata":{},"source":["## Assigning Path for Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_dir = './data'\n","train_path = './data/Train'\n","test_path = './data/Test'\n","\n","# Resizing the images to 30x30x3\n","IMG_HEIGHT = 30\n","IMG_WIDTH = 30\n","channels = 3"]},{"cell_type":"markdown","metadata":{},"source":["## Finding Total Classes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["NUM_CATEGORIES = len(os.listdir(train_path))\n","NUM_CATEGORIES"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Label Overview\n","classes = { 0:'Speed limit (20km/h)',\n","            1:'Speed limit (30km/h)', \n","            2:'Speed limit (50km/h)', \n","            3:'Speed limit (60km/h)', \n","            4:'Speed limit (70km/h)', \n","            5:'Speed limit (80km/h)', \n","            6:'End of speed limit (80km/h)', \n","            7:'Speed limit (100km/h)', \n","            8:'Speed limit (120km/h)', \n","            9:'No passing', \n","            10:'No passing veh over 3.5 tons', \n","            11:'Right-of-way at intersection', \n","            12:'Priority road', \n","            13:'Yield', \n","            14:'Stop', \n","            15:'No vehicles', \n","            16:'Veh > 3.5 tons prohibited', \n","            17:'No entry', \n","            18:'General caution', \n","            19:'Dangerous curve left', \n","            20:'Dangerous curve right', \n","            21:'Double curve', \n","            22:'Bumpy road', \n","            23:'Slippery road', \n","            24:'Road narrows on the right', \n","            25:'Road work', \n","            26:'Traffic signals', \n","            27:'Pedestrians', \n","            28:'Children crossing', \n","            29:'Bicycles crossing', \n","            30:'Beware of ice/snow',\n","            31:'Wild animals crossing', \n","            32:'End speed + passing limits', \n","            33:'Turn right ahead', \n","            34:'Turn left ahead', \n","            35:'Ahead only', \n","            36:'Go straight or right', \n","            37:'Go straight or left', \n","            38:'Keep right', \n","            39:'Keep left', \n","            40:'Roundabout mandatory', \n","            41:'End of no passing', \n","            42:'End no passing veh > 3.5 tons' }"]},{"cell_type":"markdown","metadata":{},"source":["## Visualizing The Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["folders = os.listdir(train_path)\n","\n","train_number = []\n","class_num = []\n","\n","for folder in folders:\n","    train_files = os.listdir(train_path + '/' + folder)\n","    train_number.append(len(train_files))\n","    class_num.append(classes[int(folder)])\n","    \n","# Sorting the dataset on the basis of number of images in each class\n","zipped_lists = zip(train_number, class_num)\n","sorted_pairs = sorted(zipped_lists)\n","tuples = zip(*sorted_pairs)\n","train_number, class_num = [ list(tuple) for tuple in  tuples]\n","\n","# Plotting the number of images in each class\n","plt.figure(figsize=(21,10))  \n","plt.bar(class_num, train_number)\n","plt.xticks(class_num, rotation='vertical')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualizing 25 random images from test data\n","import random\n","from matplotlib.image import imread\n","\n","test = pd.read_csv(data_dir + '/Test.csv')\n","imgs = test[\"Path\"].values\n","\n","plt.figure(figsize=(25,25))\n","\n","for i in range(1,26):\n","    plt.subplot(5,5,i)\n","    random_img_path = data_dir + '/' + random.choice(imgs)\n","    rand_img = imread(random_img_path)\n","    plt.imshow(rand_img)\n","    plt.grid(b=None)\n","    plt.xlabel(rand_img.shape[1], fontsize = 20)#width of image\n","    plt.ylabel(rand_img.shape[0], fontsize = 20)#height of image"]},{"cell_type":"markdown","metadata":{},"source":["## Collecting the Training Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","image_data = []\n","image_labels = []\n","\n","for i in range(NUM_CATEGORIES):\n","    path = data_dir + '/Train/' + str(i)\n","    images = os.listdir(path)\n","\n","    for img in images:\n","        try:\n","            image = cv2.imread(path + '/' + img)\n","            image_fromarray = Image.fromarray(image, 'RGB')\n","            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","            resize_image = np.array(resize_image)\n","            image_data.append(resize_image)\n","            image_labels.append(i)\n","        except:\n","            print(\"Error in \" + img)\n","\n","# Changing the list to numpy array\n","image_data = np.array(image_data)\n","image_labels = np.array(image_labels)\n","\n","print(image_data.shape, image_labels.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Shuffling the training data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["shuffle_indexes = np.arange(image_data.shape[0])\n","np.random.shuffle(shuffle_indexes)\n","image_data = image_data[shuffle_indexes]\n","image_labels = image_labels[shuffle_indexes]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Splitting the data into train and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n","\n","X_train = X_train/255 \n","X_val = X_val/255\n","\n","print(\"X_train.shape\", X_train.shape)\n","print(\"X_valid.shape\", X_val.shape)\n","print(\"y_train.shape\", y_train.shape)\n","print(\"y_valid.shape\", y_val.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## One hot encoding the labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_shape = y_train.shape\n","val_shape = y_val.shape\n","y_train = torch.tensor(y_train).unsqueeze_(1)\n","y_train = torch.zeros(train_shape[0], NUM_CATEGORIES).scatter_(1, y_train, 1)\n","y_val = torch.tensor(y_val).unsqueeze_(1)\n","y_val = torch.zeros(val_shape[0], NUM_CATEGORIES).scatter_(1, y_val, 1)\n","\n","X_train = torch.tensor(X_train).permute(0,3,1,2)\n","X_val = torch.tensor(X_val).permute(0,3,1,2)\n","\n","print(y_train.shape)\n","print(y_val.shape)\n","print(X_train.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Making the model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from models.model import Model\n","model = Model(NUM_CATEGORIES).cuda()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lr = 0.004\n","epochs = 30\n","\n","optimizer = torch.optim.Adam(\n","    model.parameters(), lr=lr, weight_decay=lr/(epochs*0.5))\n","#  Adam(lr=lr, decay=lr / (epochs * 0.5))\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","lr_decayer = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, 'min', factor=0.5, patience=2, verbose=True)\n","val_loss = float('Inf')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Augmenting the data and training the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from models.data_loader import MyDataLoader\n","from models.data_loader import pca\n","train_folder = MyDataLoader(X_train, y_train)\n","valid_folder = MyDataLoader(X_val, y_val)\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_folder,\n","    batch_size=32, shuffle=True,\n","    num_workers=16, pin_memory=True,\n","    drop_last=True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    valid_folder,\n","    batch_size=32, shuffle=False,\n","    num_workers=16, pin_memory=True,\n","    drop_last=False\n",")\n","\n","model.double()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for epoch in range(epochs):\n","\n","    losses = 0.\n","    precs = 0.\n","\n","    model.train()\n","\n","    for i, (input, target) in enumerate(train_loader):\n","        pca_input = input.numpy()\n","        input = []\n","        for image in pca_input:\n","            input.append(torch.tensor(pca(image)))\n","        input = torch.stack(input)\n","\n","        input = input.cuda()\n","\n","        target = target.cuda()\n","        model.zero_grad()\n","\n","        output = model(input)\n","\n","        loss = criterion(output, target)\n","\n","        prec = torch.sum(torch.argmax(output.detach().cpu(), dim=1)\n","                         == torch.argmax(target.detach().cpu(), dim=1))\n","        precs = (precs*i+prec.item())/(i+1)\n","        losses = (losses*i+loss.item())/(i+1)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 10 == 0:\n","            print('Epoch:[{0}][{1}/{2}]\\t''Loss{loss:.3f}\\t''Prec{prec:.3f}(avg:{precs:.3f})'.format(epoch, i, len(train_loader), loss=losses, prec=prec, precs=precs)\n","                  )\n","\n","    losses = 0\n","    precs=0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","            pca_input = input.numpy()\n","            input = []\n","            for image in pca_input:\n","                input.append(torch.tensor(pca(image)))\n","            input = torch.stack(input)\n","\n","            input = input.cuda()\n","\n","            target = target.cuda()\n","\n","            output = model(input)\n","\n","            loss = criterion(output, target)\n","\n","            prec = torch.sum(torch.argmax(output.detach().cpu(), dim=1)\n","                             == torch.argmax(target.detach().cpu(), dim=1))\n","            precs = (precs*i+prec.item())/(i+1)\n","            losses = (losses*i+loss.item())/(i+1)\n","\n","            if i % 10 == 0:\n","                print('Test:[{0}/{1}]\\t''Loss{loss:.3f}\\t''Prec{prec:.3f}(avg:{precs:.3f})'.format(i, len(val_loader), loss=losses, prec=prec, precs=precs)\n","                      )\n","    lr_decayer.step(losses, epoch)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save({'model':model.state_dict()},'model06012345.pth.tar')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reading model\n","\n","with open('model06012306.pth.tar','rb') as f:\n","    model.load_state_dict(torch.load(f)['model'])\n","\n","model.double()"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torchattacks\n","\n","atk = torchattacks.PGD(model, eps=8/255, alpha=2/255, steps=4)\n","# atk.set_training_mode(model_training=True, batchnorm_training=True, dropout_training=True)\n","model.train()\n","\n","precs = 0\n","losses = 0\n","for epoch in range(32):\n","    for i, (input, target) in enumerate(train_loader):\n","\n","        input = input.cuda()\n","        target = target.cuda()\n","        atk_images = atk(input, target)\n","\n","        pca_input = atk_images.detach().cpu().numpy()\n","        input = []\n","        for image in pca_input:\n","            input.append(torch.tensor(pca(image)))\n","        input = torch.stack(input).cuda()\n","        with torch.no_grad():\n","            output = model(input)\n","\n","            # for j in range(len(input)):\n","            #     cv2.imwrite('image{0}.png'.format(j),input[j].detach().cpu().permute(1,2,0).numpy()*255)\n","            #     cv2.imwrite('image{0}atk.png'.format(j),atk_images[j].detach().cpu().permute(1,2,0).numpy()*255)\n","\n","            # print(torch.argmax(target,dim=1))\n","            # print(torch.argmax(output,dim=1))\n","            # break\n","            loss = criterion(output, target)\n","\n","            prec = torch.sum(torch.argmax(output.detach().cpu(), dim=1)\n","                             == torch.argmax(target.detach().cpu(), dim=1))\n","            precs = (precs*i+prec.item())/(i+1)\n","            losses = (losses*i+loss.item())/(i+1)\n","            if i % 10 == 0:\n","                print('Epoch:[{0}][{1}/{2}]\\t''Loss{loss:.3f}\\t''Prec{prec:.3f}(avg:{precs:.3f})'.format(epoch, i, len(train_loader), loss=losses, prec=prec, precs=precs)\n","                      )\n"]}],"metadata":{"interpreter":{"hash":"2f7622ccafaa65a783a509511ee99fe2bbb086eedba98efdb0eb0bc1165f017c"},"kernelspec":{"display_name":"Python 3.8.13 ('python38')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":4}
